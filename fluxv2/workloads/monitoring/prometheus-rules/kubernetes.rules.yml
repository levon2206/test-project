apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app: kube-prometheus-stack
    release: prometheus-operator
  name: kubernetes.rules
  namespace: monitoring
spec:
  groups:
  - name: kube-state-metrics
    rules:
    - alert: Kubernetes Node ready
      annotations:
        message: Node {{ $labels.node }} has been unready for a long time
      expr: 'kube_node_status_condition{condition="Ready",status="true"} == 0'
      labels:
        severity: critical
    - alert: Kubernetes memory pressure
      annotations:
        message: "{{ $labels.node }} has MemoryPressure condition"
      expr: 'kube_node_status_condition{condition="MemoryPressure",status="true"}
        == 1'
      labels:
        severity: critical
    - alert: Kubernetes disk pressure
      annotations:
        message: "{{ $labels.node }} has DiskPressure condition"
      expr: 'kube_node_status_condition{condition="DiskPressure",status="true"}
        == 1'
      labels:
        severity: critical
    - alert: Kubernetes out of disk
      annotations:
        message: "{{ $labels.node }} has OutOfDisk condition"
      expr: 'kube_node_status_condition{condition="OutOfDisk",status="true"} ==
        1'
      labels:
        severity: critical
    - alert: Kubernetes Job failed
      annotations:
        message: "Job {{$labels.namespace}}/{{$labels.exported_job}} failed to\
          \ complete"
      expr: "kube_job_status_failed > 0"
      labels:
        severity: warning
    - alert: Kubernetes CronJob suspended
      annotations:
        message: "CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is suspended"
      expr: "kube_cronjob_spec_suspend != 0"
      labels:
        severity: warning
    - alert: Kubernetes PersistentVolumeClaim pending
      annotations:
        message: "PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim\
          \ }} is pending"
      expr: 'kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1'
      labels:
        severity: warning
    - alert: Kubernetes Volume out of disk space
      annotations:
        message: Volume is almost full (< 10% left)
      expr: "kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes\
        \ * 100 < 10"
      labels:
        severity: warning
    - alert: Kubernetes Volume full in four days
      annotations:
        message: "{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }}\
          \ is expected to fill up within four days. Currently {{ $value | humanize\
          \ }}% is available."
      expr: 'predict_linear(kubelet_volume_stats_available_bytes[6h], 4 * 24 *
        3600) < 0'
      labels:
        severity: critical
    - alert: Kubernetes PersistentVolume error
      annotations:
        message: "Persistent volume is in bad state"
      expr: 'kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"}
        > 0'
      labels:
        severity: critical
    - alert: Kubernetes StatefulSet down
      annotations:
        message: A StatefulSet went down
      expr: "(kube_statefulset_status_replicas_ready / kube_statefulset_status_replicas_current)\
        \ != 1"
      labels:
        severity: critical
    - alert: Kubernetes HPA scaling ability
      annotations:
        message: Pod is unable to scale
      expr: 'kube_hpa_status_condition{condition="false", status="AbleToScale"}
        == 1'
      labels:
        severity: warning
    - alert: Kubernetes HPA metric availability
      annotations:
        message: HPA is not able to colelct metrics
      expr: 'kube_hpa_status_condition{condition="false", status="ScalingActive"}
        == 1'
      labels:
        severity: warning
    - alert: Kubernetes HPA scale capability
      annotations:
        message: The maximum number of desired Pods has been hit
      expr: 'kube_hpa_status_desired_replicas >= kube_hpa_spec_max_replicas'
      labels:
        severity: warning
    - alert: Kubernetes Pod not healthy
      annotations:
        message: Pod has been in a non-ready state for longer than an hour.
      expr: 'min_over_time(sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"})[1h:])
        > 0'
      labels:
        severity: critical
    - alert: Kubernetes pod crash looping
      annotations:
        message: Pod {{ $labels.pod }} is crash looping
      expr: 'rate(kube_pod_container_status_restarts_total[15m]) * 60 * 5 > 5'
      labels:
        severity: warning
    - alert: Kubernetes ReplicasSet mismatch
      annotations:
        message: Deployment Replicas mismatch
      expr: 'kube_replicaset_spec_replicas != kube_replicaset_status_ready_replicas'
      labels:
        severity: warning
    - alert: Kubernetes Deployment replicas mismatch
      annotations:
        message: Deployment Replicas mismatch
      expr: 'kube_deployment_spec_replicas != kube_deployment_status_replicas_available'
      labels:
        severity: warning
    - alert: Kubernetes StatefulSet replicas mismatch
      annotations:
        message: A StatefulSet has not matched the expected number of replicas
          for longer than 15 minutes.
      expr: 'kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas'
      labels:
        severity: warning
    - alert: Kubernetes Deployment generation mismatch
      annotations:
        message: A Deployment has failed but has not been rolled back.
      expr: 'kube_deployment_status_observed_generation != kube_deployment_metadata_generation'
      labels:
        severity: critical
    - alert: Kubernetes StatefulSet generation mismatch
      annotations:
        message: A StatefulSet has failed but has not been rolled back.
      expr: 'kube_statefulset_status_observed_generation != kube_statefulset_metadata_generation'
      labels:
        severity: critical
    - alert: Kubernetes StatefulSet update not rolled out
      annotations:
        message: StatefulSet update has not been rolled out.
      expr: 'max without (revision) (kube_statefulset_status_current_revision
        unless kube_statefulset_status_update_revision) * (kube_statefulset_replicas
        != kube_statefulset_status_replicas_updated)'
      labels:
        severity: critical
    - alert: Kubernetes DaemonSet rollout stuck
      annotations:
        message: Some Pods of DaemonSet are not scheduled or not ready
      expr: 'kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled
        * 100 < 100 or kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled
        > 0'
      labels:
        severity: critical
    - alert: Kubernetes DaemonSet misscheduled
      annotations:
        message: Some DaemonSet Pods are running where they are not supposed to
          run
      expr: 'kube_daemonset_status_number_misscheduled > 0'
      labels:
        severity: critical
    - alert: Kubernetes CronJob too long
      annotations:
        message: CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is taking
          more than 1h to complete.
      expr: 'time() - kube_cronjob_next_schedule_time > 3600'
      labels:
        severity: warning
    - alert: Kubernetes job completion
      annotations:
        message: Kubernetes Job failed to complete
      expr: 'kube_job_spec_completions - kube_job_status_succeeded > 0 or kube_job_status_failed
        > 0'
      labels:
        severity: critical
    - alert: Kubernetes API server errors
      annotations:
        message: Kubernetes API server is experiencing high error rate
      expr: 'sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[2m]))
        / sum(rate(apiserver_request_count{job="apiserver"}[2m])) * 100 > 3'
      labels:
        severity: critical
    - alert: Kubernetes API client errors
      annotations:
        message: Kubernetes API client is experiencing high error rate
      expr: '(sum(rate(rest_client_requests_total{code=~"(4|5).."}[2m])) by (instance,
        job) / sum(rate(rest_client_requests_total[2m])) by (instance, job)) *
        100 > 1'
      labels:
        severity: critical
    - alert: Kubernetes client certificate expires next week
      annotations:
        message: A client certificate used to authenticate to the apiserver is
          expiring next week.
      expr: 'apiserver_client_certificate_expiration_seconds_count{job="apiserver"}
        > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m])))
        < 7*24*60*60'
      labels:
        severity: warning
    - alert: Kubernetes client certificate expires soon
      annotations:
        message: A client certificate used to authenticate to the apiserver is
          expiring in less than 24.0 hours.
      expr: 'apiserver_client_certificate_expiration_seconds_count{job="apiserver"}
        > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m])))
        < 24*60*60'
      labels:
        severity: critical
    - alert: Kubernetes API server latency
      annotations:
        message: 'Kubernetes API server has a 99th percentile latency of {{ $value
          }} seconds for {{ $labels.verb }} {{ $labels.resource }}.'
      expr: 'histogram_quantile(0.99, sum(apiserver_request_latencies_bucket{verb!~"CONNECT|WATCHLIST|WATCH|PROXY"})
        WITHOUT (instance, resource)) / 1e+06 > 1'
      labels:
        severity: warning